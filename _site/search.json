[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Karl Forner’s blog",
    "section": "",
    "text": "Organizing R development using srcpkgs\n\n\n\n\n\n\nR\n\n\nsrcpkgs\n\n\ndev\n\n\n\n\n\n\n\n\n\nMay 27, 2024\n\n\nKarl Forner\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Organizing R development using srcpkgs",
    "section": "",
    "text": "Overview\nThis is about how to organize R projects in order to:\n\nreuse code\nshare code\nincrease robustness\nenable analysis (code) reproducibility\nhave fun\n\nThe context is mostly for analysis oriented R projects.\n\n\nR packages\nAll R users use R packages, the core ones such as base, stats, tools, and some from CRAN or BioConductor.\nWhy would you want to use R packages for your own code???\na R package is:\n\nself-contained\n\nit bundles together all related code, the documentation, the relevant data and tests\n\nthe dependencies are explicitly stated, and are themselves R packages\n\n\n\nOn the natural evolution of code projects…\nThe general evolution of analysis projects:\n\nyou start with a single script, sequential, with no functions\nat one point (after writing hundreds or thousands of lines) you realize that you need some functions\nthen you start reusing those functions across projects by copy/paste. This raises a number of problems\n\nversioning: at one point you will fix or improve such a function\n\nit may be difficult to remember which project contains the latest version\nwhat of the projects that contain the incorrect versions?\n\n\nthen you may want want, if you work in a team, to share this code with colleagues, or to use theirs\n\n–&gt; it requires some documentation, even terse.\nthere’s a increased responsibility. What if your code is wrong and impact the projects of your colleagues? One remedy is to write tests for those function\nthose functions are seldom independent, so that you can not just pick one\nall those functions are exposed (i.e public or exported).\n\nif you start to use a low-level function in your project, and that in the next version the has been refactored and that this function has been changed, or removed, it breaks your project\n\n\nfor all those reasons you start packaging your reusable code into a R package\n\nyou can add documentation, tests, group code. It brings a namespace so that you can decide what you expose\n\nBut… it does really solve the versioning problem\n\nin R, packages have to be installed (e.g. using install.packages()) before you can use them with library(mypkg)\nof course packages have a version number (N.B: this is not the same as code versioning)\nif you use version v1 in your project A, and version v2 in project B, you have to juggle with versions (install/uninstall) Of course there are some tools to deal with that (renv…) but they work with external packages (or you need some private custom repositories)\nand it’s very cumbersome. Suppose that in your project A you find a bug in the (installed package). In order to fix it, you need to\n\nfetch the source code of the package\ntry to reproduce your problem. Chances are that you need your project data, you have to reproduce your session\nfinally, if you manage to fix it. You have to publish it, install it.\n\n\nmy proposal is to use what I call R source packages\n\nbasically they are R packages, that you do not need to install on your R system, but can be directly loaded from source in your R session.\nit was made possible by the infamous Hadley Wickham, and his devtools::load_all() function, that mimics the loading of an installed package\nthis greatly helps with all those problems:\n\nyou embed your source packages inside your project (as git submodules, we’ll that see later) this solves the versioning/reproducibiliy at your reusable code level: all your projects may use a different version\n\nif you need to fix a bug, or improve and augment your reusable code, it’s a simple as editing the code for your project. And using srcpkgs, you can even easily reload the code inside your existing R sessions, without losing any computed data.\nso far so good. Then for ease of maintenance/modularity, you start splitting your resuable code by category, and develop several R packages, e.g. one for some misc utilities, one for loading data from your database, one for some specific analysis…\n\nthis is where srcpkgs become useful, since devtools was designed to manage a single R source package, not a collection/library of possible inter-dependent packages.\nadditionally has a useful little hack that enables you to use the standard library() function to load your source packages. So that when you analysis is finalized, or deployed in production, with your packages installed in the standard way, your script will continue to worl without any change.\n\nBut this does not solve the reproducibility for the external packages\n\nyour code and source library most certainly use external packages, and also depend on your R version (and as such in the bioconductor version)\nit may also depend on your OS architecture (CPU…)\nthis out of scope for that talk, but one solution for that is to use a virtualized development environment: a docker container (cf https://rocker-project.org/) that contains a fixed version, and all the external packages that you need.\n\nhere the challenge is to synchronize that docker container version with your source library version…\n\n\n\n\nHence this evolution\nscript (no function) --&gt; functions --&gt; script + source files --&gt;  R package --&gt; R source package --&gt; R source library [ + R docker env]\n\n\nMy ideal project setup\n\nthe project code\n\nMUST be a git repository (in github/gitlab…)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Just started… Will try to post stuff that matters to me…"
  },
  {
    "objectID": "posts/organizing_dev_with_srcpkgs/index.html",
    "href": "posts/organizing_dev_with_srcpkgs/index.html",
    "title": "Organizing R development using srcpkgs",
    "section": "",
    "text": "Some notes for a talk about srcpkgs for the Vital-IT Analysts meeting\n\nOverview\nThis is about how to organize R projects in order to:\n\nreuse code\nshare code\nincrease robustness\nenable analysis (code) reproducibility\nhave fun\n\nThe context is mostly for analysis oriented R projects.\n\n\nR packages\nAll R users use R packages, the core ones such as base, stats, tools, and some from CRAN or BioConductor.\nWhy would you want to use R packages for your own code???\na R package is:\n\nself-contained\n\nit bundles together all related code, the documentation, the relevant data and tests\n\nthe dependencies are explicitly stated, and are themselves R packages\n\n\n\nOn the natural evolution of code projects…\nThe general evolution of analysis projects:\n\nyou start with a single script, sequential, with no functions\nat one point (after writing hundreds or thousands of lines) you realize that you need some functions\nthen you start reusing those functions across projects by copy/paste. This raises a number of problems\n\nversioning: at one point you will fix or improve such a function\n\nit may be difficult to remember which project contains the latest version\nwhat of the projects that contain the incorrect versions?\n\n\nthen you may want want, if you work in a team, to share this code with colleagues, or to use theirs\n\n–&gt; it requires some documentation, even terse.\nthere’s a increased responsibility. What if your code is wrong and impact the projects of your colleagues? One remedy is to write tests for those function\nthose functions are seldom independent, so that you can not just pick one\nall those functions are exposed (i.e public or exported).\n\nif you start to use a low-level function in your project, and that in the next version the has been refactored and that this function has been changed, or removed, it breaks your project\n\n\nfor all those reasons you start packaging your reusable code into a R package\n\nyou can add documentation, tests, group code. It brings a namespace so that you can decide what you expose\n\nBut… it does really solve the versioning problem\n\nin R, packages have to be installed (e.g. using install.packages()) before you can use them with library(mypkg)\nof course packages have a version number (N.B: this is not the same as code versioning)\nif you use version v1 in your project A, and version v2 in project B, you have to juggle with versions (install/uninstall) Of course there are some tools to deal with that (renv…) but they work with external packages (or you need some private custom repositories)\nand it’s very cumbersome. Suppose that in your project A you find a bug in the (installed package). In order to fix it, you need to\n\nfetch the source code of the package\ntry to reproduce your problem. Chances are that you need your project data, you have to reproduce your session\nfinally, if you manage to fix it. You have to publish it, install it.\n\n\nmy proposal is to use what I call R source packages\n\nbasically they are R packages, that you do not need to install on your R system, but can be directly loaded from source in your R session.\nit was made possible by the infamous Hadley Wickham, and his devtools::load_all() function, that mimics the loading of an installed package\nthis greatly helps with all those problems:\n\nyou embed your source packages inside your project (as git submodules, we’ll that see later) this solves the versioning/reproducibiliy at your reusable code level: all your projects may use a different version\n\nif you need to fix a bug, or improve and augment your reusable code, it’s a simple as editing the code for your project. And using srcpkgs, you can even easily reload the code inside your existing R sessions, without losing any computed data.\nso far so good. Then for ease of maintenance/modularity, you start splitting your resuable code by category, and develop several R packages, e.g. one for some misc utilities, one for loading data from your database, one for some specific analysis…\n\nthis is where srcpkgs become useful, since devtools was designed to manage a single R source package, not a collection/library of possible inter-dependent packages.\nadditionally has a useful little hack that enables you to use the standard library() function to load your source packages. So that when you analysis is finalized, or deployed in production, with your packages installed in the standard way, your script will continue to worl without any change.\n\nBut this does not solve the reproducibility for the external packages\n\nyour code and source library most certainly use external packages, and also depend on your R version (and as such in the bioconductor version)\nit may also depend on your OS architecture (CPU…)\nthis out of scope for that talk, but one solution for that is to use a virtualized development environment: a docker container (cf https://rocker-project.org/) that contains a fixed version, and all the external packages that you need.\n\nhere the challenge is to synchronize that docker container version with your source library version…\n\n\n\n\nHence this evolution\nscript (no function) --&gt; functions --&gt; script + source files --&gt;  R package --&gt; R source package --&gt; R source library [ + R docker env]\n\n\nMy ideal project setup\n\nthe project code\n\nMUST be a git repository (in github/gitlab…)"
  }
]